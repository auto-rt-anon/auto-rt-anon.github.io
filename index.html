

<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents</title>

    <meta name="description" content="AutoRT">
    <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" type="image/png" href="img/logo.png">
    <!-- Place favicon.ico in the root directory -->


    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-52J0PM8XKV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-52J0PM8XKV');
</script>
	
    <style>
        .nav-pills {
          position: relative;
          display: inline;
        }
        .imtip {
          position: absolute;
          top: 0;
          left: 0;
        }
    </style>
</head>

<body>

<!--bootstrap full page image-->

<style>
    /* Custom styles to create a full-page image */
    body, html {
      height: 100%;
      margin: 0;
      padding: 0;
    }

    .full-page-image {
      background-image: url('img/rt2teaser3.jpg');
      background-size: cover;
      background-position: center;
      height: 100%;
      width: 100%;
      position: relative;
    }

    .overlay {
      /* Add a semi-transparent overlay to the image if needed */
      background-color: rgba(0, 0, 0, 0.2);
      position: absolute;
      top: 0;
      bottom: 0;
      left: 0;
      right: 0;
      z-index: 1;
    }

    .content {
      /* Center your content vertically and horizontally */
      position: absolute;
      bottom: 0;
      /* right: 25; */
      /* transform: translate(-50%, -50%); */
      z-index: 2;
      color: #fff; /* Set the color for your content */
      background-color: rgba(0, 0, 0, 0.4);
    }

    .banner-state {
    height: 350px; /* or whatever height you want for the banner */
    transition: height 1s ease;
    }

    .no-content .content {
        opacity: 0;
        transition: opacity 1s ease;
    }

    #bg-video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
    opacity: 0;
    transition: opacity 1.0s ease;
    }
    
  </style>

<div class="full-page-image">


    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <br><strong><font size="+6">AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents</font></strong>               
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                <br>
                <li> Anonymous authors</li>
                		<br><br>
                  
                </ul>
            </div>
        </div>

        
        <div class="row">
                <div class="col-md-12 text-center" style="width:600px; margin: 0 auto;">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="assets/autort.pdf">
                                <image src="img/paper.png" height="60px">
                                    <h4><strong>Paper</strong></h4>
                                </a>
                            </li>
                           
                        </ul>
                </div>
        </div>

           
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
             

                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                  Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multiple buildings and collecting 77k real robot episodes via both teleoperation and autonomous robot policies. We experimentally show that such “in-the-wild” data collected by AutoRT is significantly more diverse, and that AutoRT’s use of LLMs allows for instruction following data collection robots that are aligned with human preferences.
                </p>       
             
            </div>
        </div>
                        
</div>
</div>        
</body>
<script>

    timeoutIds = [];


    function populateInstruction(imgs) {
        var qa = imgs.alt.split("[sep]");
        var instruction_buttons = document.getElementById("instruction_buttons");
        
        instruction_buttons.innerHTML = `
        <p></p>
                <button type="button" class="btn btn-primary" id="instruction1" onclick="populateDemo(this)">Candidate Instruction 1</button>
                <button type="button" class="btn btn-primary" id="instruction2" onclick="populateDemo(this)">Candidate Instruction 2</button>
                <button type="button" class="btn btn-primary hidden" id="instruction3" onclick="populateDemo(this)">Candidate Instruction 3</button>
        <p></p>
        `
        var instruction1 = document.getElementById("instruction1");
        var instruction2 = document.getElementById("instruction2");
        var instruction3 = document.getElementById("instruction3");
        instruction1.innerHTML = qa[0].split(";")[0];
        instruction1.imgs = imgs;
        instruction1.video_path = "videos/demos/" + qa[0].split(";")[1];
        instruction1.result = qa[0].split(";")[2];
        instruction2.innerHTML = qa[1].split(";")[0];
        instruction2.imgs = imgs;
        instruction2.video_path = "videos/demos/" + qa[1].split(";")[1];
        instruction2.result = qa[1].split(";")[2];
        console.log(qa.length);

        if (qa.length > 2) {
            instruction3.innerHTML = qa[2].split(";")[0];
            instruction3.imgs = imgs;
            instruction3.video_path = "videos/demos/" + qa[2].split(";")[1];
            instruction3.result = qa[2].split(";")[2];
            instruction3.classList.remove("hidden");
        }

        reset();
    }

    function reset() {
        var expandImg = document.getElementById("expandedImg");
        // Get the image text
        var imgText = document.getElementById("imgtext");
        var answer = document.getElementById("answer");
        var video = document.getElementById('demo-video');

        expandImg.src = '#';
        imgText.innerHTML = "Prompt text in gray.";
        answer.innerHTML = "RT2 response shown within code block.";
        video.pause();
        video.load();
    }

    function populateDemo(button) {
        // Get the expanded image
        var expandImg = document.getElementById("expandedImg");
        // Get the image text
        var imgText = document.getElementById("imgtext");
        var answer = document.getElementById("answer");

        // Use the same src in the expanded image as the image being clicked on from the grid
        expandImg.src = button.video_path;
        var video = document.getElementById('demo-video');
        // or video = $('.video-selector')[0];
        video.pause()
        video.load();
        video.play();
        video.removeAttribute('controls');
        
        console.log(expandImg.src);
        // Use the value of the alt attribute of the clickable image as text inside the expanded image
        var task = button.innerHTML;
        imgText.innerHTML = task;
        answer.innerHTML = "";
        // Show the container element (hidden with CSS)
        expandImg.parentElement.style.display = "block";
        for (timeoutId of timeoutIds) {
            clearTimeout(timeoutId);
        }
        typeWriter(button.result, 0, task);
    }

    function typeWriter(txt, i, q) {
        var imgText = document.getElementById("imgtext");
        if (imgText.innerHTML == q) {
            if (i < txt.length) {
                if (txt.charAt(i) == "L") {
                    answer.innerHTML = "";
                    i += 1;
                } else {
                    answer.innerHTML += txt.charAt(i);
                }
                i++;
                timeoutIds.push(setTimeout(typeWriter, 5, txt, i, q));
            }
        }
    }

    document.addEventListener('DOMContentLoaded', function() {
    const videoElement = document.getElementById('bg-video');

    // When the video metadata is loaded
    videoElement.addEventListener('loadedmetadata', function() {
        // Start playing the video
        // videoElement.play();
        // Gradually fade in the video after it finishes loading
        videoElement.style.opacity = 1.0;
        });
    });
    
    window.addEventListener("scroll", function() {
    let imageDiv = document.querySelector('.full-page-image');
    const videoElement = document.getElementById('bg-video');
    


    if (window.scrollY > 75) { 
        videoElement.style.opacity = 0; 
    }
    // Check if page is scrolled
    if (window.scrollY > 200) { // You can adjust this value based on your requirement
        imageDiv.classList.add('banner-state');
        imageDiv.classList.add('no-content');
        imageDiv.style.backgroundImage = `url(img/teaser4.jpg)`;
    };
});


</script>

</html>
